{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mtscott321/Reinforcement2048/blob/main/reinforcement_2048.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "393ab026"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "import random\n",
        "from google.colab import files\n",
        "import pandas as pd"
      ],
      "id": "393ab026"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5e949ffc"
      },
      "outputs": [],
      "source": [
        "LAYER_1 = 12\n",
        "LAYER_2 = 12\n",
        "LAYER_3 = 12\n",
        "LAYER_4 = 12"
      ],
      "id": "5e949ffc"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "f4bb1718"
      },
      "outputs": [],
      "source": [
        "class PolicyNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PolicyNet, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(16, LAYER_1)  # all the values at each of the 16 locations\n",
        "        self.fc2 = nn.Linear(LAYER_1, LAYER_2)\n",
        "        self.fc3 = nn.Linear(LAYER_2, LAYER_3)\n",
        "        self.fc4 = nn.Linear(LAYER_3, LAYER_4)\n",
        "        self.fc5 = nn.Linear(LAYER_4, 4)  # Pre-probability of N, S, E, W (not in that order)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x = torch.softmax(self.fc5(x),dim=-1) \n",
        "        # x = torch.sigmoid(self.fc3(x)) # Alternative: Categorical just needs positive inputs\n",
        "        return x"
      ],
      "id": "f4bb1718"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fc759e46"
      },
      "outputs": [],
      "source": [
        "#evaluate the vector like a left swipe (<--)\n",
        "def init():\n",
        "    #making grid\n",
        "    vals = np.zeros((4, 4), dtype = int)\n",
        "    \n",
        "    #starting values\n",
        "    new_number(vals)\n",
        "    new_number(vals)\n",
        "    \n",
        "    vals = torch.tensor(vals)\n",
        "    \n",
        "    return vals\n",
        "\n",
        "def eval_vector(v):\n",
        "    #remove spaces to compress\n",
        "    def compress(v):\n",
        "        temp = [x for x in v if x!=0]\n",
        "        v = np.zeros(4)\n",
        "        v[0:len(temp)] = temp\n",
        "        return v\n",
        "    \n",
        "    v = compress(v)\n",
        "    \n",
        "    #only go to three because we are looking to see if the ith will combine with the i+1th\n",
        "    for i in range(3):\n",
        "        if v[i] == v[i+1]:\n",
        "            v[i] = v[i] *2\n",
        "            v[i+1] = 0\n",
        "            v = compress(v)\n",
        "            \n",
        "    return v\n",
        "\n",
        "def update(updated, move):\n",
        "    if type(updated) == type(np.ndarray([0])): #I don't know how but it keeps reverting to numpy array\n",
        "        updated = torch.from_numpy(updated)\n",
        "    for i in range(4):\n",
        "        #up\n",
        "        if move == 0:\n",
        "            temp = eval_vector(updated[:, i])\n",
        "            updated[:, i] = torch.from_numpy(temp)\n",
        "\n",
        "        #left\n",
        "        elif move == 1:\n",
        "            temp = eval_vector(updated[i, :])\n",
        "            updated[i, :] = torch.from_numpy(temp)\n",
        "\n",
        "        #down\n",
        "        elif move == 2:\n",
        "            temp = eval_vector(np.flip(updated[:, i].numpy()))\n",
        "            updated[:, i] = torch.from_numpy(np.flip(temp).copy())\n",
        "        #right\n",
        "        else: \n",
        "            temp = eval_vector(np.flip(updated[i, :].numpy()))\n",
        "            updated[i, :] = torch.from_numpy(np.flip(temp).copy())\n",
        "\n",
        "    rew = sum(updated.flatten())\n",
        "    score = max(updated.flatten())   \n",
        "\n",
        "    return updated, rew, score\n",
        "            \n",
        "def new_number(vals): \n",
        "    possibles = [i for i in range(len(vals.flatten())) if vals.flatten()[i] == 0]\n",
        "    #starting values\n",
        "    x = random.sample(possibles, 1)[0] #pick without replacement\n",
        "    a = random.randint(1, 2) #pick with replacement\n",
        "    vals[int(x/4), x%4] = a*2\n",
        "    return vals\n",
        "    \n",
        "def check_valid_move(vals, i):\n",
        "    updated = vals.numpy().copy()\n",
        "    update(updated, i)\n",
        "    empty = len([i for i in range(len(updated.flatten())) if updated.flatten()[i] == 0])\n",
        "    if empty != 0 and updated != vals: #if not everything is empty after our move (if a new thing can generate without killing us) and the move actually did something\n",
        "        return True #if possible, return yes for possible move\n",
        "    return False\n",
        "    \n",
        "def check_alive(vals):\n",
        "    empty = len([i for i in range(len(vals.flatten())) if vals.flatten()[i] == 0])\n",
        "    if empty == 0:\n",
        "        possible = False\n",
        "        i = 0\n",
        "        while not possible and i < 4:\n",
        "            updated = vals.numpy().copy() #we don't want to perform this operation on the actual vals array\n",
        "            update(updated, i)\n",
        "            empty = len([i for i in range(len(updated.flatten())) if updated.flatten()[i] == 0])\n",
        "            if empty != 0:\n",
        "                possible = True\n",
        "            i += 1\n",
        "        if not possible:\n",
        "            return False #if there are no possible moves, we're dead\n",
        "    return True #if there are still empty cells, we're alive\n",
        "\n",
        "\n",
        "def display(vals):\n",
        "    color_dict = {\n",
        "    0:  '#ffffff',\n",
        "    2: '#cfcfcf',\n",
        "    4: '#b0b0b0',\n",
        "    8: '#ffdf4f',\n",
        "    16: '#ffbc4f',\n",
        "    32: '#ff924f',\n",
        "    64: '#ff6f4f',\n",
        "    128: '#ffdf4f',\n",
        "    256: '#ffbc4f',\n",
        "    512: '#ff924f',\n",
        "    1048: '#ff6f4f',\n",
        "    2048: '#ffdf4f',       \n",
        "    }\n",
        "\n",
        "    #making the color array\n",
        "    colors = np.empty((4, 4), dtype = object)\n",
        "    for i in range(4):\n",
        "        for j in range(4):\n",
        "            colors[i, j] = color_dict[vals[i, j]]\n",
        "\n",
        "\n",
        "    fig,ax = plt.subplots(figsize =(4, 4))\n",
        "    the_table = ax.table(vals, loc = 'center', cellColours = colors)\n",
        "    the_table.auto_set_font_size(False)\n",
        "    the_table.set_fontsize(15)\n",
        "    ax.axes.xaxis.set_visible(False)\n",
        "    ax.axes.yaxis.set_visible(False)\n",
        "    cell_height = 1 / 4\n",
        "    for pos, cell in the_table.get_celld().items():\n",
        "        cell.set_height(cell_height)"
      ],
      "id": "fc759e46"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "55022f1a",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def play():\n",
        "    r = 0\n",
        "    states = []\n",
        "    actions = []\n",
        "    vals = init()\n",
        "    alive = True\n",
        "    while alive:\n",
        "        p = net(vals.flatten().float()) #get the next move distribution\n",
        "        m = Categorical(p).sample() #pick next move\n",
        "        valid = check_valid_move(vals, m)\n",
        "        if valid:\n",
        "            vals, rew, score = update(vals, m) #get the most recent score\n",
        "            vals = new_number(vals)\n",
        "            alive = check_alive(vals)\n",
        "        vals_reshape = vals.reshape(16).float()\n",
        "        states.append(vals_reshape)\n",
        "        actions.append(m)\n",
        "    return states, actions, rew, score"
      ],
      "id": "55022f1a"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rKRvQNdkj6Y",
        "outputId": "b01a0444-0d2c-4068-9d89-ccf7631f5bb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "\"\"\"\n",
        "Loading a saved state from previous training\n",
        "\"\"\"\n",
        "net = PolicyNet()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.0025)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = F\"/content/drive/My Drive/Colab Notebooks/2048/2048_state.pth\"\n",
        "net.load_state_dict(torch.load(path))"
      ],
      "id": "6rKRvQNdkj6Y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8d77d84c"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Loading previous scores for graphing purposes (if we get disconnected, want to show all the training in the past, not just from this session)\n",
        "\"\"\"\n",
        "df = pd.read_excel(F\"/content/drive/My Drive/Colab Notebooks/2048/score_sheet.xlsx\")\n",
        "highScores = df[\"HighScores\"]\n",
        "avgScores = df[\"AverageScores\"]"
      ],
      "id": "8d77d84c"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "#This is to start a new one if you don't want to do it from existing state. Commented to avoid accidentally overwriting existing training\n",
        "net = PolicyNet()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.0025)\n",
        "highScores = []\n",
        "avgScores = []\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "hITyc6B1traj",
        "outputId": "811af552-7bbc-4590-d28e-b4bde7b3dfde"
      },
      "id": "hITyc6B1traj",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n#This is to start a new one if you don't want to do it from existing state. Commented to avoid accidentally overwriting existing training\\nnet = PolicyNet()\\noptimizer = torch.optim.Adam(net.parameters(), lr=0.0025)\\nhighScores = []\\navgScores = []\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28332ca0"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Now, train the model!\n",
        "\"\"\"\n",
        "\n",
        "losses = []\n",
        "EPOCHS = 1000\n",
        "BATCH_SIZE = 300\n",
        "\n",
        "for i in range(EPOCHS):\n",
        "\n",
        "    # Create a batch\n",
        "    states_batch = []\n",
        "    actions_batch = []\n",
        "    rewards_batch = []\n",
        "    scores_batch = []\n",
        "    \n",
        "    for j in range(BATCH_SIZE):\n",
        "        states, actions, rew, score = play()\n",
        "        states_batch.append(states)\n",
        "        actions_batch.append(actions)\n",
        "        rewards_batch.append(rew)\n",
        "        scores_batch.append(score) #this is just for plotting later; not involved in training\n",
        "    #formatting these tensors\n",
        "    states_batch = [torch.stack(states_batch[i]) for i in range(len(states_batch))]\n",
        "    actions_batch = [torch.stack(actions_batch[i]).long() for i in range(len(actions_batch))]\n",
        "    rewards_batch= torch.FloatTensor(rewards_batch)\n",
        "    \n",
        "    # Estimate gradient (there is probably a nice torch way to compute the log_probs)\n",
        "    outputs = outputs = [net(states_batch[i]) for i in range(len(states_batch))] #pdf outputs for all the states we were in\n",
        "    log_probs = log_probs = [Categorical(outputs[i]).log_prob(actions_batch[i]) for i in range (len(outputs))] #get the log probs of selecting the ones that were selected\n",
        "    log_means = [log_probs[i].mean() for i in range(len(log_probs))]\n",
        "    log_means = torch.stack(log_means)\n",
        "    loss = (-rewards_batch* log_means).mean()\n",
        "    losses.append(loss.detach())\n",
        "      \n",
        "    # Backprop gradient and take an optimization step\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward(retain_graph = True)\n",
        "    optimizer.step()    \n",
        "\n",
        "    highScores.append(max(scores_batch))\n",
        "    avgScores.append(sum(scores_batch)/len(scores_batch))\n",
        "\n",
        "    #save the scores to excel file\n",
        "    df = pd.DataFrame({\"HighScores\" : highScores, \"AverageScores\": avgScores})\n",
        "    df.to_excel(F\"/content/drive/My Drive/Colab Notebooks/2048/score_sheet.xlsx\")\n",
        "\n",
        "    #save the state\n",
        "    path = F\"/content/drive/My Drive/Colab Notebooks/2048/2048_state.pth\" \n",
        "    torch.save(net.state_dict(), path)\n",
        "\n",
        "    #plot the data (update the plot)\n",
        "    plt.cla()\n",
        "    plt.plot(highScores, label = \"High Score\")\n",
        "    plt.plot(avgScores, label = \"Average Score\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Scores over Time\\n Highest Score Ever: %d\" % max(highScores))\n",
        "    plt.savefig(F\"/content/drive/My Drive/Colab Notebooks/2048/highscores.jpg\")\n",
        "    sys.stdout.write(\"\\rEpoch %d: Loss: %f      \" % (i,loss))\n",
        "\n",
        "plt.show()\n"
      ],
      "id": "28332ca0"
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "reinforcement_2048.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "default_kernel",
      "language": "python",
      "name": "myenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}